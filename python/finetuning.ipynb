{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all-MiniLM-L6-v2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name model/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded with 10 records\n",
      "\n",
      "Sample data:\n",
      "      app_name                                      keywords  \\\n",
      "0        Agoda   hotel booking, travel, accommodation, deals   \n",
      "1  Booking.com  hotel reservation, travel, lodging, vacation   \n",
      "2    Hotel.com          hotel search, booking, travel, rooms   \n",
      "\n",
      "                                         description  \n",
      "0  Book hotels and accommodations worldwide with ...  \n",
      "1  Find and book hotels, apartments, and vacation...  \n",
      "2  Search and reserve hotels globally with compet...  \n",
      "\n",
      "Columns: ['app_name', 'keywords', 'description']\n",
      "Loaded 10 apps from dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name model/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 keyword groups\n",
      "Processing keyword group: hotel booking, travel, accommodation, deals with 1 apps\n",
      "Processing keyword group: hotel reservation, travel, lodging, vacation with 1 apps\n",
      "Processing keyword group: hotel search, booking, travel, rooms with 1 apps\n",
      "Processing keyword group: music streaming, playlist, audio, songs with 1 apps\n",
      "Processing keyword group: navigation, maps, travel, directions with 1 apps\n",
      "Processing keyword group: ride sharing, transportation, travel, taxi with 1 apps\n",
      "Processing keyword group: travel booking, hotels, flights, vacation with 1 apps\n",
      "Processing keyword group: travel reviews, hotels, booking, tourism with 1 apps\n",
      "Processing keyword group: travel search, hotels, flights, deals with 1 apps\n",
      "Processing keyword group: video streaming, movies, series, entertainment with 1 apps\n",
      "Generating additional training pairs since we have few examples...\n",
      "Created 90 training examples\n",
      "Created 90 training examples\n",
      "Split data into 72 training and 18 validation examples\n",
      "Creating dataloader with 72 training examples\n",
      "Fine-tuning the model on 72 examples with 18 validation examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Playstore-eval Pearson Cosine</th>\n",
       "      <th>Playstore-eval Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1.0 completed. Evaluation score: nan (Best: -1.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:203: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson, _ = pearsonr(labels, scores)\n",
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:204: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman, _ = spearmanr(labels, scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2.0 completed. Evaluation score: nan (Best: -1.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:203: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson, _ = pearsonr(labels, scores)\n",
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:204: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman, _ = spearmanr(labels, scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3.0 completed. Evaluation score: nan (Best: -1.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:203: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson, _ = pearsonr(labels, scores)\n",
      "/Users/hissain/git/github/AndroidSemanticSearch/.venv/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:204: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman, _ = spearmanr(labels, scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed successfully\n",
      "\n",
      "--- Testing Original Model ---\n",
      "Test apps:\n",
      "1. Kayak (Category: travel search, hotels, flights, deals)\n",
      "2. Booking.com (Category: hotel reservation, travel, lodging, vacation)\n",
      "3. Expedia (Category: travel booking, hotels, flights, vacation)\n",
      "4. Agoda (Category: hotel booking, travel, accommodation, deals)\n",
      "5. Netflix (Category: video streaming, movies, series, entertainment)\n",
      "\n",
      "Similarity matrix:\n",
      "Kayak vs Booking.com: 0.4822 ✗\n",
      "  Same category: False\n",
      "Kayak vs Expedia: 0.4000 ✗\n",
      "  Same category: False\n",
      "Kayak vs Agoda: 0.4131 ✗\n",
      "  Same category: False\n",
      "Kayak vs Netflix: 0.1676 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Expedia: 0.4725 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Agoda: 0.5680 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Netflix: 0.3295 ✗\n",
      "  Same category: False\n",
      "Expedia vs Agoda: 0.4455 ✗\n",
      "  Same category: False\n",
      "Expedia vs Netflix: 0.1903 ✗\n",
      "  Same category: False\n",
      "Agoda vs Netflix: 0.1755 ✗\n",
      "  Same category: False\n",
      "\n",
      "--- Testing Fine-tuned Model ---\n",
      "Test apps:\n",
      "1. Agoda (Category: hotel booking, travel, accommodation, deals)\n",
      "2. Booking.com (Category: hotel reservation, travel, lodging, vacation)\n",
      "3. Kayak (Category: travel search, hotels, flights, deals)\n",
      "4. Expedia (Category: travel booking, hotels, flights, vacation)\n",
      "5. Spotify (Category: music streaming, playlist, audio, songs)\n",
      "\n",
      "Similarity matrix:\n",
      "Agoda vs Booking.com: 0.8323 ✗\n",
      "  Same category: False\n",
      "Agoda vs Kayak: 0.7482 ✗\n",
      "  Same category: False\n",
      "Agoda vs Expedia: 0.7577 ✗\n",
      "  Same category: False\n",
      "Agoda vs Spotify: 0.6330 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Kayak: 0.8187 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Expedia: 0.8013 ✗\n",
      "  Same category: False\n",
      "Booking.com vs Spotify: 0.6759 ✗\n",
      "  Same category: False\n",
      "Kayak vs Expedia: 0.7950 ✗\n",
      "  Same category: False\n",
      "Kayak vs Spotify: 0.6495 ✗\n",
      "  Same category: False\n",
      "Expedia vs Spotify: 0.6513 ✗\n",
      "  Same category: False\n",
      "Saving fine-tuned model to fine_tuned_minilm\n",
      "\n",
      "--- Model Comparison ---\n",
      "Computing embeddings with original model...\n",
      "Computing embeddings with fine-tuned model...\n",
      "\n",
      "Similarity Comparison (Original vs Fine-tuned):\n",
      "Agoda Hotel Booking vs Booking.com Hotels:\n",
      "  Original: 0.6789, Fine-tuned: 0.7220\n",
      "  Change: 0.0431 ↑\n",
      "Agoda Hotel Booking vs Hotel.com Reservations:\n",
      "  Original: 0.6393, Fine-tuned: 0.7041\n",
      "  Change: 0.0648 ↑\n",
      "Agoda Hotel Booking vs Facebook Social Media:\n",
      "  Original: 0.0414, Fine-tuned: 0.1888\n",
      "  Change: 0.1475 ↑\n",
      "Agoda Hotel Booking vs Twitter Social Networking:\n",
      "  Original: 0.0024, Fine-tuned: 0.1342\n",
      "  Change: 0.1318 ↑\n",
      "Agoda Hotel Booking vs Calculator App:\n",
      "  Original: 0.0990, Fine-tuned: 0.1749\n",
      "  Change: 0.0759 ↑\n",
      "Agoda Hotel Booking vs Weather Forecast:\n",
      "  Original: 0.0853, Fine-tuned: 0.1510\n",
      "  Change: 0.0657 ↑\n",
      "Booking.com Hotels vs Hotel.com Reservations:\n",
      "  Original: 0.8830, Fine-tuned: 0.9069\n",
      "  Change: 0.0239 ↑\n",
      "Booking.com Hotels vs Facebook Social Media:\n",
      "  Original: 0.1241, Fine-tuned: 0.3197\n",
      "  Change: 0.1956 ↑\n",
      "Booking.com Hotels vs Twitter Social Networking:\n",
      "  Original: 0.0505, Fine-tuned: 0.2334\n",
      "  Change: 0.1829 ↑\n",
      "Booking.com Hotels vs Calculator App:\n",
      "  Original: 0.1506, Fine-tuned: 0.2481\n",
      "  Change: 0.0975 ↑\n",
      "Booking.com Hotels vs Weather Forecast:\n",
      "  Original: 0.0282, Fine-tuned: 0.1040\n",
      "  Change: 0.0758 ↑\n",
      "Hotel.com Reservations vs Facebook Social Media:\n",
      "  Original: 0.1463, Fine-tuned: 0.3155\n",
      "  Change: 0.1692 ↑\n",
      "Hotel.com Reservations vs Twitter Social Networking:\n",
      "  Original: 0.0685, Fine-tuned: 0.2264\n",
      "  Change: 0.1579 ↑\n",
      "Hotel.com Reservations vs Calculator App:\n",
      "  Original: 0.1285, Fine-tuned: 0.2236\n",
      "  Change: 0.0951 ↑\n",
      "Hotel.com Reservations vs Weather Forecast:\n",
      "  Original: 0.0118, Fine-tuned: 0.0934\n",
      "  Change: 0.0816 ↑\n",
      "Facebook Social Media vs Twitter Social Networking:\n",
      "  Original: 0.7719, Fine-tuned: 0.8057\n",
      "  Change: 0.0337 ↑\n",
      "Facebook Social Media vs Calculator App:\n",
      "  Original: 0.1011, Fine-tuned: 0.1748\n",
      "  Change: 0.0737 ↑\n",
      "Facebook Social Media vs Weather Forecast:\n",
      "  Original: 0.0607, Fine-tuned: 0.1142\n",
      "  Change: 0.0535 ↑\n",
      "Twitter Social Networking vs Calculator App:\n",
      "  Original: 0.0675, Fine-tuned: 0.1294\n",
      "  Change: 0.0620 ↑\n",
      "Twitter Social Networking vs Weather Forecast:\n",
      "  Original: 0.1473, Fine-tuned: 0.1807\n",
      "  Change: 0.0333 ↑\n",
      "Calculator App vs Weather Forecast:\n",
      "  Original: 0.0437, Fine-tuned: 0.0856\n",
      "  Change: 0.0419 ↑\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "# Use correct path or download from web directly\n",
    "print(\"Loading all-MiniLM-L6-v2 model...\")\n",
    "model = SentenceTransformer('model/all-MiniLM-L6-v2')  # Using the model name directly to download\n",
    "\n",
    "def load_your_dataset():\n",
    "    try:\n",
    "        df = pd.read_csv('dataset/apps.csv')\n",
    "        print(f\"Dataset loaded with {len(df)} records\")\n",
    "        # Print the first few rows to understand the structure\n",
    "        print(\"\\nSample data:\")\n",
    "        print(df.head(3))\n",
    "        print(\"\\nColumns:\", df.columns.tolist())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        # Create a sample dataset for testing\n",
    "        print(\"Creating sample dataset for testing...\")\n",
    "        sample_df = pd.DataFrame({\n",
    "            'app_name': [\n",
    "                'Facebook', 'Instagram', 'Twitter', \n",
    "                'Booking.com', 'Agoda', 'Hotels.com',\n",
    "                'Calculator', 'Calendar', 'Weather'\n",
    "            ],\n",
    "            'description': [\n",
    "                'Social media platform to connect with friends', \n",
    "                'Photo sharing social network',\n",
    "                'Microblogging social platform',\n",
    "                'Hotel booking and travel app',\n",
    "                'Hotel reservations and deals',\n",
    "                'Book rooms and accommodations',\n",
    "                'Simple calculator app',\n",
    "                'Manage your schedule',\n",
    "                'Weather forecasts and alerts'\n",
    "            ],\n",
    "            'keywords': [\n",
    "                'Social', 'Social', 'Social',\n",
    "                'Travel', 'Travel', 'Travel',\n",
    "                'Utility', 'Utility', 'Utility'\n",
    "            ]\n",
    "        })\n",
    "        return sample_df\n",
    "\n",
    "def create_training_examples(df):\n",
    "    training_examples = []\n",
    "    \n",
    "    # Check if we have the expected columns\n",
    "    required_columns = ['app_name', 'description', 'keywords']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Warning: Missing columns: {missing_columns}\")\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        print(\"Creating alternative examples based on available data\")\n",
    "        \n",
    "        # Create examples using whatever columns are available\n",
    "        all_apps = df.to_dict('records')\n",
    "        \n",
    "        # Create positive pairs using any common column\n",
    "        if 'keywords' in df.columns:\n",
    "            keyword_groups = df.groupby('keywords')\n",
    "        elif 'category' in df.columns:\n",
    "            keyword_groups = df.groupby('category')\n",
    "        else:\n",
    "            # Just create random pairs if no grouping column exists\n",
    "            print(\"No grouping column found. Creating random pairs...\")\n",
    "            for i in range(len(df)):\n",
    "                for j in range(i+1, min(i+5, len(df))):\n",
    "                    app1 = all_apps[i]\n",
    "                    app2 = all_apps[j]\n",
    "                    \n",
    "                    text1 = f\"{app1.get('app_name', '')} {app1.get('description', '')}\"\n",
    "                    text2 = f\"{app2.get('app_name', '')} {app2.get('description', '')}\"\n",
    "                    \n",
    "                    training_examples.append(InputExample(texts=[text1, text2], label=0.8))\n",
    "            \n",
    "            # Create some negative examples\n",
    "            for _ in range(len(training_examples)):\n",
    "                i, j = random.sample(range(len(all_apps)), 2)\n",
    "                app1 = all_apps[i]\n",
    "                app2 = all_apps[j]\n",
    "                \n",
    "                text1 = f\"{app1.get('app_name', '')} {app1.get('description', '')}\"\n",
    "                text2 = f\"{app2.get('app_name', '')} {app2.get('description', '')}\"\n",
    "                \n",
    "                training_examples.append(InputExample(texts=[text1, text2], label=0.2))\n",
    "            \n",
    "            return training_examples\n",
    "    \n",
    "    # Standard example creation with expected columns\n",
    "    keyword_groups = df.groupby('keywords')\n",
    "    \n",
    "    print(f\"Found {len(keyword_groups)} keyword groups\")\n",
    "    \n",
    "    # Create positive pairs (apps with similar keywords/descriptions)\n",
    "    for keyword, group in keyword_groups:\n",
    "        print(f\"Processing keyword group: {keyword} with {len(group)} apps\")\n",
    "        if len(group) > 1:  # Need at least 2 apps for pairs\n",
    "            app_list = group.to_dict('records')\n",
    "            for i in range(len(app_list)):\n",
    "                for j in range(i + 1, len(app_list)):\n",
    "                    app1 = app_list[i]\n",
    "                    app2 = app_list[j]\n",
    "                    \n",
    "                    # Combine app_name with description for richer context\n",
    "                    text1 = f\"{app1['app_name']} {app1['description']}\"\n",
    "                    text2 = f\"{app2['app_name']} {app2['description']}\"\n",
    "                    \n",
    "                    # Score: 1.0 for apps with same keywords (positive pairs)\n",
    "                    training_examples.append(InputExample(texts=[text1, text2], label=1.0))\n",
    "    \n",
    "    # Create negative pairs from different keyword groups\n",
    "    all_apps = df.to_dict('records')\n",
    "    \n",
    "    # If we have too few examples (less than 10), generate more pairs\n",
    "    if len(training_examples) < 10:\n",
    "        print(\"Generating additional training pairs since we have few examples...\")\n",
    "        for i in range(len(df)):\n",
    "            for j in range(len(df)):\n",
    "                if i != j:\n",
    "                    app1 = all_apps[i]\n",
    "                    app2 = all_apps[j]\n",
    "                    \n",
    "                    text1 = f\"{app1['app_name']} {app1['description']}\"\n",
    "                    text2 = f\"{app2['app_name']} {app2['description']}\"\n",
    "                    \n",
    "                    # Assign higher score if same keyword group, lower otherwise\n",
    "                    if app1['keywords'] == app2['keywords']:\n",
    "                        score = 0.9\n",
    "                    else:\n",
    "                        score = 0.1\n",
    "                    \n",
    "                    training_examples.append(InputExample(texts=[text1, text2], label=score))\n",
    "    else:\n",
    "        # Add some negative examples if we already have sufficient positive examples\n",
    "        for _ in range(min(len(training_examples), 100)):  # Limit to reasonable number\n",
    "            app1, app2 = random.sample(all_apps, 2)\n",
    "            # Ensure different keywords for negative pairs\n",
    "            if app1['keywords'] != app2['keywords']:\n",
    "                text1 = f\"{app1['app_name']} {app1['description']}\"\n",
    "                text2 = f\"{app2['app_name']} {app2['description']}\"\n",
    "                training_examples.append(InputExample(texts=[text1, text2], label=0.0))\n",
    "    \n",
    "    print(f\"Created {len(training_examples)} training examples\")\n",
    "    return training_examples\n",
    "\n",
    "def split_examples(examples, train_ratio=0.8):\n",
    "    \"\"\"Split examples into training and validation sets\"\"\"\n",
    "    if not examples:\n",
    "        print(\"Warning: No examples to split!\")\n",
    "        # Create some dummy examples to avoid errors\n",
    "        return create_dummy_examples(), create_dummy_examples()\n",
    "        \n",
    "    random.shuffle(examples)\n",
    "    split_idx = max(1, int(len(examples) * train_ratio))  # Ensure at least 1 example in each split\n",
    "    return examples[:split_idx], examples[split_idx:] or examples[:1]  # Use first example as validation if needed\n",
    "\n",
    "def create_dummy_examples():\n",
    "    \"\"\"Create dummy examples for testing when no real data is available\"\"\"\n",
    "    print(\"Creating dummy examples for demonstration...\")\n",
    "    dummy_examples = [\n",
    "        InputExample(texts=[\"Hotel booking app\", \"Travel booking service\"], label=1.0),\n",
    "        InputExample(texts=[\"Social media app\", \"Photo sharing platform\"], label=0.8),\n",
    "        InputExample(texts=[\"Calculator app\", \"Hotel booking service\"], label=0.1),\n",
    "    ]\n",
    "    return dummy_examples\n",
    "\n",
    "class CustomCallback:\n",
    "    \"\"\"Custom callback to display progress during training\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.best_score = -1\n",
    "        \n",
    "    def __call__(self, score, epoch, steps):\n",
    "        \"\"\"This method is called by the SentenceTransformer framework\"\"\"\n",
    "        self.epoch = epoch\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "        print(f\"\\nEpoch {epoch} completed. Evaluation score: {score:.4f} (Best: {self.best_score:.4f})\")\n",
    "\n",
    "# 4. Fine-tuning function\n",
    "def fine_tune_model(model, train_examples, val_examples, output_path='fine_tuned_minilm'):\n",
    "    \"\"\"Fine-tune the model with proper error handling\"\"\"\n",
    "    if not train_examples:\n",
    "        print(\"No training examples available. Skipping fine-tuning.\")\n",
    "        return model\n",
    "        \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path) if '/' in output_path else '.', exist_ok=True)\n",
    "    \n",
    "    # Define train dataset and dataloader\n",
    "    print(f\"Creating dataloader with {len(train_examples)} training examples\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_examples,\n",
    "        shuffle=True,\n",
    "        batch_size=min(16, len(train_examples))  # Adjust batch size for small datasets\n",
    "    )\n",
    "    \n",
    "    train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "    \n",
    "    # Handle empty validation set\n",
    "    if not val_examples:\n",
    "        print(\"No validation examples available. Using training examples for validation.\")\n",
    "        val_examples = train_examples[:min(len(train_examples), 3)]\n",
    "        \n",
    "    evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "        val_examples,\n",
    "        name='playstore-eval'\n",
    "    )\n",
    "    \n",
    "    callback = CustomCallback()\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    print(f\"Fine-tuning the model on {len(train_examples)} examples with {len(val_examples)} validation examples...\")\n",
    "    \n",
    "    try:\n",
    "        model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            evaluator=evaluator,\n",
    "            epochs=3,\n",
    "            warmup_steps=10,  # Reduce for small datasets\n",
    "            output_path=output_path,\n",
    "            show_progress_bar=True,\n",
    "            callback=callback\n",
    "        )\n",
    "        print(\"Fine-tuning completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fine-tuning: {e}\")\n",
    "        print(\"Continuing with original model\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compare_models(original_model, fine_tuned_model, test_sentences):\n",
    "    \"\"\"Compare embeddings from original and fine-tuned models\"\"\"\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    \n",
    "    # Encode with original model\n",
    "    print(\"Computing embeddings with original model...\")\n",
    "    original_embeddings = original_model.encode(test_sentences)\n",
    "    original_similarities = util.cos_sim(original_embeddings, original_embeddings)\n",
    "    \n",
    "    # Encode with fine-tuned model\n",
    "    print(\"Computing embeddings with fine-tuned model...\")\n",
    "    fine_tuned_embeddings = fine_tuned_model.encode(test_sentences)\n",
    "    fine_tuned_similarities = util.cos_sim(fine_tuned_embeddings, fine_tuned_embeddings)\n",
    "    \n",
    "    # Compare similarities\n",
    "    print(\"\\nSimilarity Comparison (Original vs Fine-tuned):\")\n",
    "    for i in range(len(test_sentences)):\n",
    "        for j in range(i + 1, len(test_sentences)):\n",
    "            orig_sim = original_similarities[i][j].item()\n",
    "            ft_sim = fine_tuned_similarities[i][j].item()\n",
    "            diff = ft_sim - orig_sim\n",
    "            change = \"↑\" if diff > 0 else \"↓\"\n",
    "            \n",
    "            print(f\"{test_sentences[i]} vs {test_sentences[j]}:\")\n",
    "            print(f\"  Original: {orig_sim:.4f}, Fine-tuned: {ft_sim:.4f}\")\n",
    "            print(f\"  Change: {abs(diff):.4f} {change}\")\n",
    "\n",
    "def test_model(model, df, name=\"Model\"):\n",
    "    \"\"\"Test model on dataset samples\"\"\"\n",
    "    # Handle small datasets\n",
    "    sample_size = min(5, len(df))\n",
    "    if sample_size == 0:\n",
    "        print(f\"No data to test {name}\")\n",
    "        return\n",
    "        \n",
    "    test_apps = df.sample(sample_size)\n",
    "    app_texts = []\n",
    "    \n",
    "    for _, app in test_apps.iterrows():\n",
    "        # Handle missing columns\n",
    "        app_name = app.get('app_name', 'Unknown App')\n",
    "        description = app.get('description', '')\n",
    "        app_texts.append(f\"{app_name} {description}\")\n",
    "    \n",
    "    print(f\"\\n--- Testing {name} ---\")\n",
    "    print(\"Test apps:\")\n",
    "    for i, (_, app) in enumerate(test_apps.iterrows()):\n",
    "        keywords = app.get('keywords', 'Unknown')\n",
    "        print(f\"{i+1}. {app.get('app_name', 'App')} (Category: {keywords})\")\n",
    "    \n",
    "    # Calculate embeddings and similarities\n",
    "    embeddings = model.encode(app_texts, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(embeddings, embeddings)\n",
    "    \n",
    "    # Print similarities between apps\n",
    "    print(\"\\nSimilarity matrix:\")\n",
    "    for i, row1 in enumerate(test_apps.iterrows()):\n",
    "        _, app1 = row1\n",
    "        for j, row2 in enumerate(test_apps.iterrows()):\n",
    "            _, app2 = row2\n",
    "            if i < j:\n",
    "                sim_value = similarities[i][j].item()\n",
    "                # Handle missing columns\n",
    "                app1_keywords = app1.get('keywords', None)\n",
    "                app2_keywords = app2.get('keywords', None)\n",
    "                same_category = app1_keywords == app2_keywords if app1_keywords and app2_keywords else \"Unknown\"\n",
    "                marker = \"✓\" if same_category is True else \"✗\" if same_category is False else \"?\"\n",
    "                \n",
    "                print(f\"{app1.get('app_name', 'App1')} vs {app2.get('app_name', 'App2')}: {sim_value:.4f} {marker}\")\n",
    "                print(f\"  Same category: {same_category}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load your dataset\n",
    "        print(\"Loading dataset...\")\n",
    "        df = load_your_dataset()\n",
    "        print(f\"Loaded {len(df)} apps from dataset\")\n",
    "        \n",
    "        # Save original model for comparison later\n",
    "        original_model = SentenceTransformer('model/all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Prepare training data\n",
    "        train_examples = create_training_examples(df)\n",
    "        print(f\"Created {len(train_examples)} training examples\")\n",
    "        \n",
    "        # Handle case with no training examples\n",
    "        if not train_examples:\n",
    "            print(\"No training examples were created. Creating dummy examples...\")\n",
    "            train_examples = create_dummy_examples()\n",
    "        \n",
    "        # Split into train and validation sets\n",
    "        train_examples, val_examples = split_examples(train_examples)\n",
    "        print(f\"Split data into {len(train_examples)} training and {len(val_examples)} validation examples\")\n",
    "        \n",
    "        # Fine-tune the model\n",
    "        fine_tuned_model = fine_tune_model(model, train_examples, val_examples)\n",
    "        \n",
    "        # Test both models on the same data for comparison\n",
    "        test_model(original_model, df, name=\"Original Model\")\n",
    "        test_model(fine_tuned_model, df, name=\"Fine-tuned Model\")\n",
    "        \n",
    "        # Save the model\n",
    "        output_path = 'fine_tuned_minilm'\n",
    "        print(f\"Saving fine-tuned model to {output_path}\")\n",
    "        fine_tuned_model.save(output_path)\n",
    "        \n",
    "        # Example usage with specific test cases\n",
    "        test_sentences = [\n",
    "            \"Agoda Hotel Booking\",\n",
    "            \"Booking.com Hotels\", \n",
    "            \"Hotel.com Reservations\",\n",
    "            \"Facebook Social Media\",\n",
    "            \"Twitter Social Networking\",\n",
    "            \"Calculator App\",\n",
    "            \"Weather Forecast\"\n",
    "        ]\n",
    "        \n",
    "        # Compare original and fine-tuned models\n",
    "        compare_models(original_model, fine_tuned_model, test_sentences)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
